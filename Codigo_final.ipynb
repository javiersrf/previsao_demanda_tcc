{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "joba2AvQH-No",
        "Yv-pK0YEII5Y",
        "ZhPOHAEJNN_V",
        "MMm0TN_KIBau",
        "Ll905P5ZKOjp",
        "yd6vEHleOrh5",
        "kjxcEXjIOZqK"
      ],
      "authorship_tag": "ABX9TyPBi2G+l3gvZA3smXt/G23z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/javiersrf/previsao_demanda_tcc/blob/main/Codigo_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importacoes"
      ],
      "metadata": {
        "id": "joba2AvQH-No"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuKfm1lbpprd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.model_selection import TimeSeriesSplit"
      ],
      "metadata": {
        "id": "imLQtRMgGDM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definicao de funcoes uteis"
      ],
      "metadata": {
        "id": "Yv-pK0YEII5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(df, column):\n",
        "  # One Hot Encoded na coluna\n",
        "  one_hot_df = pd.get_dummies(df[column], prefix=column)\n",
        "  df_encoded = pd.concat([df, one_hot_df], axis=1)\n",
        "  df_encoded = df_encoded.drop(columns=column)\n",
        "  return df_encoded\n",
        "\n",
        "def parse_dataframe(data):\n",
        "  copy_data = data.copy()\n",
        "  copy_data[\"data_saida\"] = pd.to_datetime(copy_data[\"data_saida\"])\n",
        "  copy_data = copy_data[copy_data[\"id_cliente\"].notnull()]\n",
        "  copy_data = copy_data.drop(copy_data[copy_data[\"preco_saida\"] == 0].index)\n",
        "  copy_data = copy_data.drop(copy_data[copy_data[\"preco_total\"] == 0].index)\n",
        "  copy_data[\"data_saida\"] = pd.to_datetime(copy_data[\"data_saida\"])\n",
        "  copy_data[\"year\"] = copy_data[\"data_saida\"].dt.year\n",
        "  copy_data[\"month\"] = copy_data[\"data_saida\"].dt.month\n",
        "  uniques_ids_grouped_by_month = copy_data.groupby(['year', 'month', 'id_produto_saida', ])['id_cliente'].nunique().reset_index()\n",
        "\n",
        "  df_merged = pd.merge(copy_data, uniques_ids_grouped_by_month, on=['year', 'month', 'id_produto_saida'])\n",
        "  df_merged = df_merged.rename(columns={\n",
        "      \"id_cliente_x\":\"id_cliente\",\n",
        "      \"id_cliente_y\":\"quant_clientes_mes\"\n",
        "  })\n",
        "  # Agrupando por mes\n",
        "  df_grouped  = df_merged.groupby(['year', 'month', 'id_produto_saida', \"quant_clientes_mes\"]).agg({\n",
        "    \"preco_saida\":\"mean\",\n",
        "    \"quantidade_saida\":\"sum\",\n",
        "    \"preco_total\":\"sum\",\n",
        "  }).reset_index()\n",
        "  final_data = one_hot_encode(df_grouped, \"id_produto_saida\")\n",
        "  return final_data"
      ],
      "metadata": {
        "id": "hEC-3GERu-se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_date_from_month_year(df):\n",
        "  df['date'] = pd.to_datetime(df[['year', 'month']].assign(Day=1)).dt.date\n",
        "  df = df.sort_values(\"date\")\n",
        "  return df\n",
        "data = create_date_from_month(data)"
      ],
      "metadata": {
        "id": "ycHL_HyRL9Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InputData:\n",
        "  def __init__(self, year, month, product_id, clients_amount, total_price, price) -> None:\n",
        "    self.year = year\n",
        "    self.month = month\n",
        "    self.product_id = product_id\n",
        "    self.clients_amount = clients_amount\n",
        "    self.total_price = total_price\n",
        "    self.price = price\n",
        "\n",
        "  def encode_product(self, product_id):\n",
        "    products_columns = {column: 0 for column in data.columns if \"id_produto_saida_\" in column}\n",
        "    products_columns[\"id_produto_saida_\"+str(product_id)] = 1\n",
        "    return [item for key, item in products_columns.items()]\n",
        "\n",
        "  @property\n",
        "  def to_input(self):\n",
        "    return np.array([\n",
        "        self.year,\n",
        "        self.month,\n",
        "        self.clients_amount,\n",
        "        self.price,\n",
        "        self.total_price,\n",
        "        *self.encode_product(self.product_id)\n",
        "    ])"
      ],
      "metadata": {
        "id": "WLuomk_gJfqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregamento Global"
      ],
      "metadata": {
        "id": "ZhPOHAEJNN_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Carregando arquivo**"
      ],
      "metadata": {
        "id": "ctrZvaRLIWZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/demand_by_month.xlsx\").drop(columns=\"Unnamed: 0\")"
      ],
      "metadata": {
        "id": "ET-JlSzEH_6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dividindo os dados de teste e treino a partir da data selecionada**"
      ],
      "metadata": {
        "id": "dmjZOK7iIpPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "divisor =  \"2022-01-01\"\n",
        "train = index_data[index_data[\"data\"] < split_date]\n",
        "train.to_excel(\"train_data.xlsx\")\n",
        "test = index_data[index_data[\"data\"] >= split_date]\n",
        "test.to_excel(\"test_data.xlsx\")"
      ],
      "metadata": {
        "id": "utB1uB_EGyQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning"
      ],
      "metadata": {
        "id": "MMm0TN_KIBau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parseando campo de data para formato datetime**"
      ],
      "metadata": {
        "id": "vaqjgJqwIh7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_data = data.copy()\n",
        "index_data[\"data\"] =  data[\"month\"].astype(str) + \"-1-\"+ data[\"year\"].astype(str)\n",
        "index_data[\"data\"] = pd.to_datetime(index_data[\"data\"])"
      ],
      "metadata": {
        "id": "AFmZWo1AUBrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Treinando modelos**"
      ],
      "metadata": {
        "id": "bqkDOguYTO2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = \"quantidade_saida\"\n",
        "predicts = {}\n",
        "scores_ = []\n",
        "seed = 7\n",
        "_models = {}\n",
        "_models[\"KNR\"] = KNeighborsRegressor()\n",
        "_models[\"LR\"] = LinearRegression()\n",
        "_models[\"RG\"] = Ridge()\n",
        "_models[\"LSVR\"] = LinearSVR()\n",
        "_models[\"DTR\"] = DecisionTreeRegressor()\n",
        "_models[\"RFR\"] = RandomForestRegressor()\n",
        "_models[\"GBR\"] = GradientBoostingRegressor()\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in _models.items():\n",
        "  X_train, X_test = train.drop([target, \"data\"], axis=1).values, test.drop([target, \"data\"], axis=1).values\n",
        "  y_train, y_test = train[target].values, test[target].values\n",
        "  # evaluate each model in turn\n",
        "  results = []\n",
        "  names = []\n",
        "  scoring = 'accuracy'\n",
        "  model.fit(X_train, y_train)\n",
        "  score = model.score(X_test, y_test)*100\n",
        "  scores_.append((name, score))\n",
        "  msg = \"%s: %f %%\" % (name, score.mean())\n",
        "  print(msg)\n",
        "  predicts[name] = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "eVP-zJwBH6jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validando resultado**"
      ],
      "metadata": {
        "id": "MfKBRLcTKZCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = _models[\"GBR\"].predict(X_test)\n",
        "plt.plot(y_test.values)\n",
        "plt.plot(y_predict)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8AhX-EpPKbf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=y_predict, y=y_test.values)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5ZskWy90KnU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Salvando resultados em um arquivo**"
      ],
      "metadata": {
        "id": "RxLAVRfqKK33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, values in predicts.items():\n",
        "  test[name] = values\n",
        "test.to_excel(\"results_ml.xlsx\")"
      ],
      "metadata": {
        "id": "VngcnA_H4Ry5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metodos Estatisticos"
      ],
      "metadata": {
        "id": "Ll905P5ZKOjp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Copiando dados para uma nova variavel e revertento o \"one hot encoding\"**"
      ],
      "metadata": {
        "id": "uuwrgx3eMKC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "statistic_data = data.copy()\n",
        "dummies_columns = [col for col in statistic_data.columns if \"id_produto_saida_\" in col]\n",
        "def find_product_id(df):\n",
        "  for col in dummies_columns:\n",
        "    if df[col] == 1:\n",
        "      return int(col[17:])\n",
        "data[\"id_produto_saida\"] = statistic_data.apply(find_product_id, axis=1)\n",
        "reverted_data = statistic_data.drop(columns=dummies_columns)"
      ],
      "metadata": {
        "id": "xkNw83CFKSEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definindo apenas os produtos de categoria A como estudo**"
      ],
      "metadata": {
        "id": "layr2RLjMqTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ONLY_A_PRODUCTS = True\n",
        "if ONLY_A_PRODUCTS:\n",
        "  PRODUCTS_IDS = [132,148,129,133,108,100,130,134,98,131,147]\n",
        "else:\n",
        "  PRODUCTS_IDS = list(reverted_data[\"id_produto_saida\"].unique())"
      ],
      "metadata": {
        "id": "f5cesreZMfmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analise de demanda total pelo tempo**"
      ],
      "metadata": {
        "id": "B1KS4c3IMzdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reverted_data[reverted_data[\"id_produto_saida\"].isin(PRODUCTS_IDS)].groupby([\"year\", \"month\"]).agg({\"preco_total\":\"sum\"}).plot()"
      ],
      "metadata": {
        "id": "-JMecZm8M18F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prevendo usando modelos estatisticos**"
      ],
      "metadata": {
        "id": "l6MNGT1BMY6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_values  = []\n",
        "for product_id in [PRODUCTS_IDS]:\n",
        "  data_product = reverted_data[reverted_data[\"id_produto_saida\"] == product_id][[\"id_produto_saida\", \"quantidade_saida\", \"date\", \"year\", \"month\"]]\n",
        "  monthly_data_product = data_product.groupby([\"year\", \"month\", \"id_produto_saida\"]).agg({\"quantidade_saida\":\"sum\"}).reset_index()\n",
        "  monthly_data_product['date'] = pd.to_datetime(monthly_data_product[['year', 'month']].assign(Day=1)).dt.date\n",
        "  monthly_data_product = monthly_data_product.sort_values(\"date\")\n",
        "  monthly_data_product.head(5)\n",
        "  #media movel simples\n",
        "  for window in [3,5,7]:\n",
        "    monthly_data_product[f'moving_avg_{window}'] = monthly_data_product['quantidade_saida'].rolling(window=window).mean()\n",
        "\n",
        "\n",
        "  ##media movel ponderada\n",
        "  pesos_n = {\n",
        "        2: [0.3, 0.7],\n",
        "        3: [0.2, 0.3, 0.5],\n",
        "        4: [0.1, 0.2, 0.3, 0.4]\n",
        "    }\n",
        "  for key, value in pesos_n.items():\n",
        "    monthly_data_product[f'weighted_moving_avg_{key}'] = monthly_data_product['quantidade_saida'].rolling(window=key).apply(lambda x: np.dot(x, value), raw=True)\n",
        "\n",
        "\n",
        "  #ARIMA\n",
        "  indexed_data = monthly_data_product.copy()\n",
        "  indexed_data[\"date\"] = pd.to_datetime(indexed_data[\"date\"])\n",
        "  indexed_data = indexed_data.set_index(\"date\")\n",
        "  train = indexed_data[indexed_data.index < split_date]\n",
        "  test = indexed_data[indexed_data.index >= split_date]\n",
        "  model = None\n",
        "  model = auto_arima(train[\"quantidade_saida\"], seasonal=True, m=12)\n",
        "  forecasts = model.predict(test.shape[0])\n",
        "  temp = np.empty(len(train))\n",
        "  temp[:] = np.nan\n",
        "  temp = np.concatenate(( temp, forecasts.values))\n",
        "  monthly_data_product[\"ARIMA\"] = temp\n",
        "  results_values.append(monthly_data_product.copy())\n",
        "\n"
      ],
      "metadata": {
        "id": "eXcxMOrMNALh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Concatenar todos os resultados**"
      ],
      "metadata": {
        "id": "wEpSngIMNyqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "concact_results = pd.concat(results_values)\n",
        "estastitical_data = pd.merge(reverted_data, concact_results, how=\"left\", on=[\"year\", \"month\", \"id_produto_saida\"])"
      ],
      "metadata": {
        "id": "Lq99D8YjN0XM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Juntando resultados de M.l com estatisticos"
      ],
      "metadata": {
        "id": "yd6vEHleOrh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Limpando os valores sem um dos resultados**"
      ],
      "metadata": {
        "id": "w-rfEen5N4Wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_final_data = estastitical_data.dropna()\n"
      ],
      "metadata": {
        "id": "8OJkMnHZN6XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ml_results = test.copy()\n",
        "ml_results[\"id_produto_saida\"] = ml_results.apply(find_product_id, axis=1)\n",
        "n_ml_results = ml_results.drop(columns=dummies_columns)\n",
        "final = pd.merge(clean_final_data, n_ml_results, on=[\"year\", \"month\", \"quant_clientes_mes\", \"id_produto_saida\"], how=\"left\")\n",
        "final = final.drop(columns=[col for col in final.columns if \"_x\" in col or \"_y\" in col])\n",
        "final.tail(4)\n",
        "real_value = 'quantidade_saida'\n",
        "columns_with_results = [\n",
        "    'moving_avg_3', 'moving_avg_5', 'moving_avg_7', 'weighted_moving_avg_2',\n",
        "    'weighted_moving_avg_3', 'weighted_moving_avg_4', 'ARIMA',\n",
        "    'KNR', 'LR', 'RG', 'LSVR', 'DTR', 'RFR',\n",
        "    'GBR']"
      ],
      "metadata": {
        "id": "W9F-miZlN8zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analisando resultado pelo erro"
      ],
      "metadata": {
        "id": "kjxcEXjIOZqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tipos de erro**"
      ],
      "metadata": {
        "id": "STgBKEZDOCux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mape(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
        "def calculate_rmse(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.sqrt(np.mean(pow((y_true - y_pred),2)))"
      ],
      "metadata": {
        "id": "oREasdYNODak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "erro_data = []\n",
        "product = None\n",
        "data_produto = final.copy()\n",
        "data_produto['data'] = pd.to_datetime(data_produto['year'].astype(str) + '-' + data_produto['month'].astype(str) + '-01')\n",
        "erro_data = [\n",
        "    [\"MAPE\", *[str(calculate_mape(data_produto[real_value], data_produto[algo])).replace(\".\", \",\") for algo in columns_with_results]],\n",
        "    [\"RMSE\", *[str(calculate_rmse(data_produto[real_value], data_produto[algo])).replace(\".\", \",\") for algo in columns_with_results]]\n",
        "]\n",
        "erro_df = pd.DataFrame(\n",
        "    erro_data,\n",
        "    columns=[\"Metodo\", \"Media Movel 3\",\"Media Movel 5\",\"Media Movel 7\", \"Media Movel Ponderada 2\",\"Media Movel Ponderada 3\",\"Media Movel Ponderada 4\",\"ARIMA\",\t\"KNR\",\t\"LR\",\t\"RG\",\t\"LSVR\",\t\"DTR\",\t\"RFR\",\t\"GBR\"],\n",
        "\n",
        ")\n",
        "erro_df.to_excel(\"erro_total_result.xlsx\")"
      ],
      "metadata": {
        "id": "GxgNDPrhOPtc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}